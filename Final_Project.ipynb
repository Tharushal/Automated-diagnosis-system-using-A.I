{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tharushal/Automated-diagnosis-system-using-A.I/blob/master/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1yMV8fa1Qyj",
        "colab_type": "text"
      },
      "source": [
        "Install Faiss,TF,git datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoW0kvS71mDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To use CPU FAISS use\n",
        "!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "#To use GPU FAISS use\n",
        "# !wget  https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl\n",
        "\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install https://github.com/re-search/DocProduct/archive/v0.2.0_dev.zip\n",
        "!pip install gpt2-estimator\n",
        "!pip install pyarrow\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLwBr-nB0IJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC_l8b8kLm9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install Flask-JSON\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNFFDSWJ2c9u",
        "colab_type": "text"
      },
      "source": [
        "Downaload all model checkpoints, and question/answer data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Jk1mgr2l4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "                \n",
        "import os\n",
        "import requests\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "# Download the file from `url` and save it locally under `file_name`:\n",
        "urllib.request.urlretrieve('https://github.com/naver/biobert-pretrained/releases/download/v1.0-pubmed-pmc/biobert_v1.0_pubmed_pmc.tar.gz', 'BioBert.tar.gz')\n",
        "\n",
        "if not os.path.exists('BioBertFolder'):\n",
        "    os.makedirs('BioBertFolder')\n",
        "    \n",
        "import tarfile\n",
        "tar = tarfile.open(\"BioBert.tar.gz\")\n",
        "tar.extractall(path='BioBertFolder/')\n",
        "tar.close()\n",
        "\n",
        "file_id = '1uCXv6mQkFfpw5txGnVCsl93Db7t5Z2mp'\n",
        "\n",
        "download_file_from_google_drive(file_id, 'Float16EmbeddingsExpanded5-27-19.pkl')\n",
        "\n",
        "file_id = 'https://onedrive.live.com/download?cid=9DEDF3C1E2D7E77F&resid=9DEDF3C1E2D7E77F%2132792&authkey=AEQ8GtkcDbe3K98'\n",
        "    \n",
        "urllib.request.urlretrieve( file_id, 'DataAndCheckpoint.zip')\n",
        "\n",
        "if not os.path.exists('newFolder'):\n",
        "    os.makedirs('newFolder')\n",
        "\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('DataAndCheckpoint.zip', 'r')\n",
        "zip_ref.extractall('newFolder')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO_rPHub24kB",
        "colab_type": "text"
      },
      "source": [
        "Load model weights and Q&A data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOVndlui287N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from docproduct.predictor import RetreiveQADoc\n",
        "\n",
        "pretrained_path = 'BioBertFolder/biobert_v1.0_pubmed_pmc/'\n",
        "# ffn_weight_file = None\n",
        "bert_ffn_weight_file = 'newFolder/models/bertffn_crossentropy/bertffn'\n",
        "embedding_file = 'Float16EmbeddingsExpanded5-27-19.pkl'\n",
        "\n",
        "doc = RetreiveQADoc(pretrained_path=pretrained_path,\n",
        "ffn_weight_file=None,\n",
        "bert_ffn_weight_file=bert_ffn_weight_file,\n",
        "embedding_file=embedding_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65gBLOUk3IFw",
        "colab_type": "text"
      },
      "source": [
        "Type in your question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYMhUWoR3MVw",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from flask import jsonify \n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "result = \"\"\n",
        "\n",
        "@app.route('/<string:question_text>', methods=['GET'])\n",
        "\n",
        "def get_answer(question_text):\n",
        "    global result\n",
        "    result=[]\n",
        "    def get_result():\n",
        "\n",
        "      search_similarity_by = 'answer'  #@param ['answer', \"question\"]\n",
        "\n",
        "      number_results_toReturn=10 #@param {type:\"number\"}\n",
        "\n",
        "      answer_only=True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "      returned_results = doc.predict( question_text ,\n",
        "                        search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "      \n",
        "\n",
        "      #print('')\n",
        "      for jk in range(len(returned_results)):\n",
        "          #print(\"Result \", jk+1)\n",
        "          #print(returned_results[jk])\n",
        "          global result\n",
        "          result.append(returned_results[jk])\n",
        "          #print('')  \n",
        "      return result\n",
        "  \n",
        "    return jsonify({\"result\": get_result()})\n",
        "  \n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}